{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fall 2024 Data Science Track: Week 2 - Data Cleaning Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages, Packages, Packages!\n",
    "\n",
    "Import *all* the things here! You need the standard stuff: `pandas` and `numpy`.\n",
    "\n",
    "If you got more stuff you want to use, add them here too. 🙂"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import here.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "With the packages out of the way, now you will be working with the following data sets:\n",
    "\n",
    "* `food_coded.csv`: [Food choices](https://www.kaggle.com/datasets/borapajo/food-choices?select=food_coded.csv) from Kaggle\n",
    "* `Ask A Manager Salary Survey 2021 (Responses) - Form Responses 1.tsv`: [Ask A Manager Salary Survey 2021 (Responses)](https://docs.google.com/spreadsheets/d/1IPS5dBSGtwYVbjsfbaMCYIWnOuRmJcbequohNxCyGVw/view?&gid=1625408792) as *Tab Separated Values (.tsv)* from Google Docs\n",
    "\n",
    "Each one poses different challenges. But you’ll―of course―overcome them with what you learned in class! 😉"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Food Choices Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Food choices data set into a variable (e.g., df_food).\n",
    "\n",
    "#put .. to make path work\n",
    "food_data_set_path = '../data/food_coded.csv'\n",
    "\n",
    "df_food = pd.read_csv(food_data_set_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much data did you just load?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125, 61)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count by hand. (lol kidding)\n",
    "\n",
    "df_food.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the columns and their types in this data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125 entries, 0 to 124\n",
      "Data columns (total 61 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   GPA                           123 non-null    object \n",
      " 1   Gender                        125 non-null    int64  \n",
      " 2   breakfast                     125 non-null    int64  \n",
      " 3   calories_chicken              125 non-null    int64  \n",
      " 4   calories_day                  106 non-null    float64\n",
      " 5   calories_scone                124 non-null    float64\n",
      " 6   coffee                        125 non-null    int64  \n",
      " 7   comfort_food                  124 non-null    object \n",
      " 8   comfort_food_reasons          123 non-null    object \n",
      " 9   comfort_food_reasons_coded    106 non-null    float64\n",
      " 10  cook                          122 non-null    float64\n",
      " 11  comfort_food_reasons_coded.1  125 non-null    int64  \n",
      " 12  cuisine                       108 non-null    float64\n",
      " 13  diet_current                  124 non-null    object \n",
      " 14  diet_current_coded            125 non-null    int64  \n",
      " 15  drink                         123 non-null    float64\n",
      " 16  eating_changes                122 non-null    object \n",
      " 17  eating_changes_coded          125 non-null    int64  \n",
      " 18  eating_changes_coded1         125 non-null    int64  \n",
      " 19  eating_out                    125 non-null    int64  \n",
      " 20  employment                    116 non-null    float64\n",
      " 21  ethnic_food                   125 non-null    int64  \n",
      " 22  exercise                      112 non-null    float64\n",
      " 23  father_education              124 non-null    float64\n",
      " 24  father_profession             122 non-null    object \n",
      " 25  fav_cuisine                   123 non-null    object \n",
      " 26  fav_cuisine_coded             125 non-null    int64  \n",
      " 27  fav_food                      123 non-null    float64\n",
      " 28  food_childhood                124 non-null    object \n",
      " 29  fries                         125 non-null    int64  \n",
      " 30  fruit_day                     125 non-null    int64  \n",
      " 31  grade_level                   125 non-null    int64  \n",
      " 32  greek_food                    125 non-null    int64  \n",
      " 33  healthy_feeling               125 non-null    int64  \n",
      " 34  healthy_meal                  124 non-null    object \n",
      " 35  ideal_diet                    124 non-null    object \n",
      " 36  ideal_diet_coded              125 non-null    int64  \n",
      " 37  income                        124 non-null    float64\n",
      " 38  indian_food                   125 non-null    int64  \n",
      " 39  italian_food                  125 non-null    int64  \n",
      " 40  life_rewarding                124 non-null    float64\n",
      " 41  marital_status                124 non-null    float64\n",
      " 42  meals_dinner_friend           122 non-null    object \n",
      " 43  mother_education              122 non-null    float64\n",
      " 44  mother_profession             123 non-null    object \n",
      " 45  nutritional_check             125 non-null    int64  \n",
      " 46  on_off_campus                 124 non-null    float64\n",
      " 47  parents_cook                  125 non-null    int64  \n",
      " 48  pay_meal_out                  125 non-null    int64  \n",
      " 49  persian_food                  124 non-null    float64\n",
      " 50  self_perception_weight        124 non-null    float64\n",
      " 51  soup                          124 non-null    float64\n",
      " 52  sports                        123 non-null    float64\n",
      " 53  thai_food                     125 non-null    int64  \n",
      " 54  tortilla_calories             124 non-null    float64\n",
      " 55  turkey_calories               125 non-null    int64  \n",
      " 56  type_sports                   99 non-null     object \n",
      " 57  veggies_day                   125 non-null    int64  \n",
      " 58  vitamins                      125 non-null    int64  \n",
      " 59  waffle_calories               125 non-null    int64  \n",
      " 60  weight                        123 non-null    object \n",
      "dtypes: float64(20), int64(27), object(14)\n",
      "memory usage: 59.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Show the column names and their types.\n",
    "\n",
    "df_food.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the Data\n",
    "\n",
    "Perhaps we’d like to know more another day, but the team is really interested in just the relationship between calories (`calories_day`) and weight. …and maybe gender."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you remove the other columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove ‘em\n",
    "\n",
    "df_food_specific = df_food[[\"calories_day\", \"weight\", \"Gender\"]].copy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about `NaN`s? How many are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPA                  2\n",
       "Gender               0\n",
       "breakfast            0\n",
       "calories_chicken     0\n",
       "calories_day        19\n",
       "                    ..\n",
       "type_sports         26\n",
       "veggies_day          0\n",
       "vitamins             0\n",
       "waffle_calories      0\n",
       "weight               2\n",
       "Length: 61, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count ‘em.\n",
    "\n",
    "\n",
    "df_food.isna().sum() \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gotta remove those `NaN`s―the entire row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GPA</th>\n",
       "      <th>Gender</th>\n",
       "      <th>breakfast</th>\n",
       "      <th>calories_chicken</th>\n",
       "      <th>calories_day</th>\n",
       "      <th>calories_scone</th>\n",
       "      <th>coffee</th>\n",
       "      <th>comfort_food</th>\n",
       "      <th>comfort_food_reasons</th>\n",
       "      <th>comfort_food_reasons_coded</th>\n",
       "      <th>...</th>\n",
       "      <th>soup</th>\n",
       "      <th>sports</th>\n",
       "      <th>thai_food</th>\n",
       "      <th>tortilla_calories</th>\n",
       "      <th>turkey_calories</th>\n",
       "      <th>type_sports</th>\n",
       "      <th>veggies_day</th>\n",
       "      <th>vitamins</th>\n",
       "      <th>waffle_calories</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.654</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>610</td>\n",
       "      <td>3.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>chocolate, chips, ice cream</td>\n",
       "      <td>Stress, bored, anger</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>725.0</td>\n",
       "      <td>690</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>900</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>720</td>\n",
       "      <td>4.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>frozen yogurt, pizza, fast food</td>\n",
       "      <td>stress, sadness</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1165.0</td>\n",
       "      <td>500</td>\n",
       "      <td>none</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>900</td>\n",
       "      <td>I'm not answering this.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>720</td>\n",
       "      <td>2.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Ice cream, chocolate, chips</td>\n",
       "      <td>Stress, boredom, cravings</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>940.0</td>\n",
       "      <td>500</td>\n",
       "      <td>Softball</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>760</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>610</td>\n",
       "      <td>3.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Chocolate, ice cream, french fries, pretzels</td>\n",
       "      <td>stress, boredom</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>940.0</td>\n",
       "      <td>690</td>\n",
       "      <td>soccer</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1315</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>720</td>\n",
       "      <td>3.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Ice cream, cheeseburgers, chips.</td>\n",
       "      <td>I eat comfort food when im stressed out from s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>725.0</td>\n",
       "      <td>500</td>\n",
       "      <td>none</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1315</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GPA  Gender  breakfast  calories_chicken  calories_day  calories_scone  \\\n",
       "1  3.654       1          1               610           3.0           420.0   \n",
       "2    3.3       1          1               720           4.0           420.0   \n",
       "4    3.5       1          1               720           2.0           420.0   \n",
       "6    3.8       2          1               610           3.0           420.0   \n",
       "7    3.3       1          1               720           3.0           420.0   \n",
       "\n",
       "   coffee                                  comfort_food  \\\n",
       "1       2                   chocolate, chips, ice cream   \n",
       "2       2               frozen yogurt, pizza, fast food   \n",
       "4       2                  Ice cream, chocolate, chips    \n",
       "6       2  Chocolate, ice cream, french fries, pretzels   \n",
       "7       1              Ice cream, cheeseburgers, chips.   \n",
       "\n",
       "                                comfort_food_reasons  \\\n",
       "1                               Stress, bored, anger   \n",
       "2                                    stress, sadness   \n",
       "4                         Stress, boredom, cravings    \n",
       "6                                    stress, boredom   \n",
       "7  I eat comfort food when im stressed out from s...   \n",
       "\n",
       "   comfort_food_reasons_coded  ...  soup  sports  thai_food tortilla_calories  \\\n",
       "1                         1.0  ...   1.0     1.0          2             725.0   \n",
       "2                         1.0  ...   1.0     2.0          5            1165.0   \n",
       "4                         1.0  ...   1.0     1.0          4             940.0   \n",
       "6                         1.0  ...   1.0     1.0          5             940.0   \n",
       "7                         1.0  ...   1.0     2.0          1             725.0   \n",
       "\n",
       "   turkey_calories  type_sports veggies_day  vitamins  waffle_calories  \\\n",
       "1              690  Basketball            4         2              900   \n",
       "2              500         none           5         1              900   \n",
       "4              500     Softball           4         2              760   \n",
       "6              690       soccer           4         1             1315   \n",
       "7              500         none           4         2             1315   \n",
       "\n",
       "                     weight  \n",
       "1                       155  \n",
       "2  I'm not answering this.   \n",
       "4                       190  \n",
       "6                       180  \n",
       "7                       137  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop ‘em.\n",
    "\n",
    "df_food_dropped = df_food.dropna()\n",
    "\n",
    "df_food_dropped.head()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what about the weird non-numeric values in the column obviously meant for numeric data?\n",
    "\n",
    "Notice the data type of that column from when you got the types of all the columns?\n",
    "\n",
    "If only we could convert the column to a numeric type and drop the rows with invalid values. 🤔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GPA</th>\n",
       "      <th>Gender</th>\n",
       "      <th>breakfast</th>\n",
       "      <th>calories_chicken</th>\n",
       "      <th>calories_day</th>\n",
       "      <th>calories_scone</th>\n",
       "      <th>coffee</th>\n",
       "      <th>comfort_food</th>\n",
       "      <th>comfort_food_reasons</th>\n",
       "      <th>comfort_food_reasons_coded</th>\n",
       "      <th>...</th>\n",
       "      <th>soup</th>\n",
       "      <th>sports</th>\n",
       "      <th>thai_food</th>\n",
       "      <th>tortilla_calories</th>\n",
       "      <th>turkey_calories</th>\n",
       "      <th>type_sports</th>\n",
       "      <th>veggies_day</th>\n",
       "      <th>vitamins</th>\n",
       "      <th>waffle_calories</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.654</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>610</td>\n",
       "      <td>3.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>chocolate, chips, ice cream</td>\n",
       "      <td>Stress, bored, anger</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>725.0</td>\n",
       "      <td>690</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>900</td>\n",
       "      <td>155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>720</td>\n",
       "      <td>2.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Ice cream, chocolate, chips</td>\n",
       "      <td>Stress, boredom, cravings</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>940.0</td>\n",
       "      <td>500</td>\n",
       "      <td>Softball</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>760</td>\n",
       "      <td>190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>610</td>\n",
       "      <td>3.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Chocolate, ice cream, french fries, pretzels</td>\n",
       "      <td>stress, boredom</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>940.0</td>\n",
       "      <td>690</td>\n",
       "      <td>soccer</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1315</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>720</td>\n",
       "      <td>3.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Ice cream, cheeseburgers, chips.</td>\n",
       "      <td>I eat comfort food when im stressed out from s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>725.0</td>\n",
       "      <td>500</td>\n",
       "      <td>none</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1315</td>\n",
       "      <td>137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>430</td>\n",
       "      <td>3.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Mac and cheese, chocolate, and pasta</td>\n",
       "      <td>Stress, anger and sadness</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>580.0</td>\n",
       "      <td>345</td>\n",
       "      <td>field hockey</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>900</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GPA  Gender  breakfast  calories_chicken  calories_day  calories_scone  \\\n",
       "1  3.654       1          1               610           3.0           420.0   \n",
       "4    3.5       1          1               720           2.0           420.0   \n",
       "6    3.8       2          1               610           3.0           420.0   \n",
       "7    3.3       1          1               720           3.0           420.0   \n",
       "9    3.3       1          1               430           3.0           315.0   \n",
       "\n",
       "   coffee                                  comfort_food  \\\n",
       "1       2                   chocolate, chips, ice cream   \n",
       "4       2                  Ice cream, chocolate, chips    \n",
       "6       2  Chocolate, ice cream, french fries, pretzels   \n",
       "7       1              Ice cream, cheeseburgers, chips.   \n",
       "9       2         Mac and cheese, chocolate, and pasta    \n",
       "\n",
       "                                comfort_food_reasons  \\\n",
       "1                               Stress, bored, anger   \n",
       "4                         Stress, boredom, cravings    \n",
       "6                                    stress, boredom   \n",
       "7  I eat comfort food when im stressed out from s...   \n",
       "9                         Stress, anger and sadness    \n",
       "\n",
       "   comfort_food_reasons_coded  ...  soup  sports  thai_food tortilla_calories  \\\n",
       "1                         1.0  ...   1.0     1.0          2             725.0   \n",
       "4                         1.0  ...   1.0     1.0          4             940.0   \n",
       "6                         1.0  ...   1.0     1.0          5             940.0   \n",
       "7                         1.0  ...   1.0     2.0          1             725.0   \n",
       "9                         1.0  ...   1.0     1.0          4             580.0   \n",
       "\n",
       "   turkey_calories   type_sports veggies_day  vitamins  waffle_calories  \\\n",
       "1              690   Basketball            4         2              900   \n",
       "4              500      Softball           4         2              760   \n",
       "6              690        soccer           4         1             1315   \n",
       "7              500          none           4         2             1315   \n",
       "9              345  field hockey           5         1              900   \n",
       "\n",
       "   weight  \n",
       "1   155.0  \n",
       "4   190.0  \n",
       "6   180.0  \n",
       "7   137.0  \n",
       "9   125.0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fix that.\n",
    "\n",
    "\n",
    "df_food[\"weight\"] = pd.to_numeric(df_food[\"weight\"], errors=\"coerce\")\n",
    "\n",
    "df_dropped= df_food.dropna().copy()\n",
    "\n",
    "df_dropped.head()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this data seems reasonably clean for our purposes! 😁\n",
    "\n",
    "Let’s save it somewhere to be shipped off to another teammate. 💾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Savey save!\n",
    "df_dropped.to_csv(\"cleaned_food_data.csv\", index= False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask a Manager Salary Survey 2021 (Responses) Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Ask A Manager Salary Survey 2021 (Responses) data set into a variable (e.g., df_salary).\n",
    "\n",
    "df_salary = pd.read_csv(\"/workspaces/ds-fall-2025-fri-1230/Week-02-Pandas-Part-2-and-DS-Overview/data/Salary_Survey_2021.csv\", sep='\\t')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was that hard? 🙃"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rename the file to something that is better for all systems.  \n",
    "* No spaces in filename (can use '_')\n",
    "* all lower case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore\n",
    "\n",
    "You know the drill."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much data did you just load?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28062, 18)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count by hand. I’m dead serious.\n",
    "\n",
    "df_salary.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the columns and their types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28062 entries, 0 to 28061\n",
      "Data columns (total 18 columns):\n",
      " #   Column                                                                                                                                                                                                                                Non-Null Count  Dtype  \n",
      "---  ------                                                                                                                                                                                                                                --------------  -----  \n",
      " 0   Timestamp                                                                                                                                                                                                                             28062 non-null  object \n",
      " 1   How old are you?                                                                                                                                                                                                                      28062 non-null  object \n",
      " 2   What industry do you work in?                                                                                                                                                                                                         27988 non-null  object \n",
      " 3   Job title                                                                                                                                                                                                                             28061 non-null  object \n",
      " 4   If your job title needs additional context, please clarify here:                                                                                                                                                                      7262 non-null   object \n",
      " 5   What is your annual salary? (You'll indicate the currency in a later question. If you are part-time or hourly, please enter an annualized equivalent -- what you would earn if you worked the job 40 hours a week, 52 weeks a year.)  28062 non-null  object \n",
      " 6   How much additional monetary compensation do you get, if any (for example, bonuses or overtime in an average year)? Please only include monetary compensation here, not the value of benefits.                                        20766 non-null  float64\n",
      " 7   Please indicate the currency                                                                                                                                                                                                          28062 non-null  object \n",
      " 8   If \"Other,\" please indicate the currency here:                                                                                                                                                                                        206 non-null    object \n",
      " 9   If your income needs additional context, please provide it here:                                                                                                                                                                      3042 non-null   object \n",
      " 10  What country do you work in?                                                                                                                                                                                                          28062 non-null  object \n",
      " 11  If you're in the U.S., what state do you work in?                                                                                                                                                                                     23039 non-null  object \n",
      " 12  What city do you work in?                                                                                                                                                                                                             27980 non-null  object \n",
      " 13  How many years of professional work experience do you have overall?                                                                                                                                                                   28062 non-null  object \n",
      " 14  How many years of professional work experience do you have in your field?                                                                                                                                                             28062 non-null  object \n",
      " 15  What is your highest level of education completed?                                                                                                                                                                                    27840 non-null  object \n",
      " 16  What is your gender?                                                                                                                                                                                                                  27891 non-null  object \n",
      " 17  What is your race? (Choose all that apply.)                                                                                                                                                                                           27885 non-null  object \n",
      "dtypes: float64(1), object(17)\n",
      "memory usage: 3.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Show the column names and their types.\n",
    "\n",
    "df_salary.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh… Ugh! Give these columns easier names to work with first. 🙄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>age</th>\n",
       "      <th>industry</th>\n",
       "      <th>title</th>\n",
       "      <th>title_context</th>\n",
       "      <th>salary</th>\n",
       "      <th>additional_compensation</th>\n",
       "      <th>currency</th>\n",
       "      <th>other_currency</th>\n",
       "      <th>salary_context</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>total_yoe</th>\n",
       "      <th>field_yoe</th>\n",
       "      <th>highest_education_completed</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4/27/2021 11:02:10</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Education (Higher Education)</td>\n",
       "      <td>Research and Instruction Librarian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55,000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>Boston</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4/27/2021 11:02:22</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Change &amp; Internal Communications Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54,600</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>GBP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cambridge</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Non-binary</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4/27/2021 11:02:38</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Accounting, Banking &amp; Finance</td>\n",
       "      <td>Marketing Specialist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34,000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>Chattanooga</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4/27/2021 11:02:41</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Nonprofits</td>\n",
       "      <td>Program Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62,000</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Milwaukee</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4/27/2021 11:02:42</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Accounting, Banking &amp; Finance</td>\n",
       "      <td>Accounting Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60,000</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>Greenville</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp    age                       industry  \\\n",
       "0  4/27/2021 11:02:10  25-34   Education (Higher Education)   \n",
       "1  4/27/2021 11:02:22  25-34              Computing or Tech   \n",
       "2  4/27/2021 11:02:38  25-34  Accounting, Banking & Finance   \n",
       "3  4/27/2021 11:02:41  25-34                     Nonprofits   \n",
       "4  4/27/2021 11:02:42  25-34  Accounting, Banking & Finance   \n",
       "\n",
       "                                      title title_context  salary  \\\n",
       "0        Research and Instruction Librarian           NaN  55,000   \n",
       "1  Change & Internal Communications Manager           NaN  54,600   \n",
       "2                      Marketing Specialist           NaN  34,000   \n",
       "3                           Program Manager           NaN  62,000   \n",
       "4                        Accounting Manager           NaN  60,000   \n",
       "\n",
       "   additional_compensation currency other_currency salary_context  \\\n",
       "0                      0.0      USD            NaN            NaN   \n",
       "1                   4000.0      GBP            NaN            NaN   \n",
       "2                      NaN      USD            NaN            NaN   \n",
       "3                   3000.0      USD            NaN            NaN   \n",
       "4                   7000.0      USD            NaN            NaN   \n",
       "\n",
       "          country           state         city     total_yoe    field_yoe  \\\n",
       "0   United States   Massachusetts       Boston     5-7 years    5-7 years   \n",
       "1  United Kingdom             NaN    Cambridge  8 - 10 years    5-7 years   \n",
       "2              US       Tennessee  Chattanooga   2 - 4 years  2 - 4 years   \n",
       "3             USA       Wisconsin    Milwaukee  8 - 10 years    5-7 years   \n",
       "4              US  South Carolina   Greenville  8 - 10 years    5-7 years   \n",
       "\n",
       "  highest_education_completed      gender   race  \n",
       "0             Master's degree       Woman  White  \n",
       "1              College degree  Non-binary  White  \n",
       "2              College degree       Woman  White  \n",
       "3              College degree       Woman  White  \n",
       "4              College degree       Woman  White  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename ‘em.\n",
    "# Non-binding suggestions: timestamp, age, industry, title, title_context, salary, additional_compensation, currency, other_currency, salary_context, country, state, city, total_yoe, field_yoe, highest_education_completed\tgender, race\n",
    "\n",
    "\n",
    "df_salary.columns = [\"timestamp\", \"age\", \"industry\", \"title\", \"title_context\", \"salary\", \"additional_compensation\", \"currency\", \"other_currency\", \"salary_context\", \"country\", \"state\", \"city\", \"total_yoe\", \"field_yoe\", \"highest_education_completed\", \"gender\", \"race\"]\n",
    "\n",
    "df_salary.head()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It’s a lot, and that should not have been easy. 😏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You’re going to have a gander at the computing/tech subset first because thats *your* industry. But first, what value corresponds to that `industry`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "industry\n",
       "Computing or Tech                        4699\n",
       "Education (Higher Education)             2464\n",
       "Nonprofits                               2419\n",
       "Health care                              1896\n",
       "Government and Public Administration     1889\n",
       "                                         ... \n",
       "Warehousing                                 1\n",
       "Education (Early Childhood Education)       1\n",
       "SAAS                                        1\n",
       "Health and Safety                           1\n",
       "Aerospace Manufacturing                     1\n",
       "Name: count, Length: 1219, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the unique industries and a count of their instances.\n",
    "\n",
    "df_salary['industry'].value_counts()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That value among the top 5 is what you’re looking for innit? Filter out all the rows not in that industry and save it into a new dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "industry\n",
       "Computing or Tech                       4699\n",
       "Education (Higher Education)            2464\n",
       "Nonprofits                              2419\n",
       "Health care                             1896\n",
       "Government and Public Administration    1889\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtery filter. (Save it to a new variable, df_salary_tech.)\n",
    "\n",
    "df_salary_tech = df_salary['industry'].value_counts().head(5)\n",
    "\n",
    "df_salary_tech.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a sanity check to make sure that the only values you kept are the one you are filtered for.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method IndexOpsMixin.value_counts of industry\n",
       "Computing or Tech                       4699\n",
       "Education (Higher Education)            2464\n",
       "Nonprofits                              2419\n",
       "Health care                             1896\n",
       "Government and Public Administration    1889\n",
       "Name: count, dtype: int64>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity Check \n",
    "\n",
    "df_salary_tech.value_counts\n",
    "\n",
    "#df_salary_tech.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are very interested in salary figures. But how many dollars 💵 is a euro 💶 or a pound 💷? That sounds like a problem for another day. 🫠\n",
    "\n",
    "For now, let’s just look at U.S. dollars (`'USD'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>age</th>\n",
       "      <th>industry</th>\n",
       "      <th>title</th>\n",
       "      <th>title_context</th>\n",
       "      <th>salary</th>\n",
       "      <th>additional_compensation</th>\n",
       "      <th>currency</th>\n",
       "      <th>other_currency</th>\n",
       "      <th>salary_context</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>total_yoe</th>\n",
       "      <th>field_yoe</th>\n",
       "      <th>highest_education_completed</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4/27/2021 11:02:10</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Education (Higher Education)</td>\n",
       "      <td>Research and Instruction Librarian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55,000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>Boston</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4/27/2021 11:02:38</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Accounting, Banking &amp; Finance</td>\n",
       "      <td>Marketing Specialist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34,000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>Chattanooga</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4/27/2021 11:02:41</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Nonprofits</td>\n",
       "      <td>Program Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62,000</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Milwaukee</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4/27/2021 11:02:42</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Accounting, Banking &amp; Finance</td>\n",
       "      <td>Accounting Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60,000</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>Greenville</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4/27/2021 11:02:46</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Education (Higher Education)</td>\n",
       "      <td>Scholarly Publishing Librarian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62,000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>Hanover</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>Man</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp    age                       industry  \\\n",
       "0  4/27/2021 11:02:10  25-34   Education (Higher Education)   \n",
       "2  4/27/2021 11:02:38  25-34  Accounting, Banking & Finance   \n",
       "3  4/27/2021 11:02:41  25-34                     Nonprofits   \n",
       "4  4/27/2021 11:02:42  25-34  Accounting, Banking & Finance   \n",
       "5  4/27/2021 11:02:46  25-34   Education (Higher Education)   \n",
       "\n",
       "                                title title_context  salary  \\\n",
       "0  Research and Instruction Librarian           NaN  55,000   \n",
       "2                Marketing Specialist           NaN  34,000   \n",
       "3                     Program Manager           NaN  62,000   \n",
       "4                  Accounting Manager           NaN  60,000   \n",
       "5      Scholarly Publishing Librarian           NaN  62,000   \n",
       "\n",
       "   additional_compensation currency other_currency salary_context  \\\n",
       "0                      0.0      USD            NaN            NaN   \n",
       "2                      NaN      USD            NaN            NaN   \n",
       "3                   3000.0      USD            NaN            NaN   \n",
       "4                   7000.0      USD            NaN            NaN   \n",
       "5                      NaN      USD            NaN            NaN   \n",
       "\n",
       "         country           state         city     total_yoe    field_yoe  \\\n",
       "0  United States   Massachusetts       Boston     5-7 years    5-7 years   \n",
       "2             US       Tennessee  Chattanooga   2 - 4 years  2 - 4 years   \n",
       "3            USA       Wisconsin    Milwaukee  8 - 10 years    5-7 years   \n",
       "4             US  South Carolina   Greenville  8 - 10 years    5-7 years   \n",
       "5            USA   New Hampshire      Hanover  8 - 10 years  2 - 4 years   \n",
       "\n",
       "  highest_education_completed gender   race  \n",
       "0             Master's degree  Woman  White  \n",
       "2              College degree  Woman  White  \n",
       "3              College degree  Woman  White  \n",
       "4              College degree  Woman  White  \n",
       "5             Master's degree    Man  White  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtery filter for just the jobs that pay in USD!\n",
    "\n",
    "filter_usa = df_salary['currency'] == 'USD'\n",
    "\n",
    "df_only_USA = df_salary[filter_usa]\n",
    "\n",
    "df_only_USA.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we really want know is how each U.S. city pays in tech. What value in `country` represents the United States of America?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country\n",
       "United States     8989\n",
       "USA               7922\n",
       "US                2606\n",
       "United States      667\n",
       "U.S.               580\n",
       "                  ... \n",
       "Saudi Arabia         1\n",
       "LOUTRELAND           1\n",
       "philippines          1\n",
       "Myanmar              1\n",
       "Burma                1\n",
       "Name: count, Length: 229, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We did filter for USD, so if we do a count of each unique country in descending count order, the relevant value(s) should show up at the top.\n",
    "\n",
    "\n",
    "df_only_USA['country'].value_counts()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the Data\n",
    "\n",
    "Well, we can’t get our answers with what we currently have, so you’ll have to make some changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s not worry about anything below the first 5 values for now. Convert the top 5 to a single canonical value―say, `'US'`, which is nice and short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_106953/1795015388.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_only_USA['country'] = df_only_USA['country'].replace(df_only_USA['country'].value_counts().head(5).index, 'US')\n"
     ]
    }
   ],
   "source": [
    "# Replace them all with 'US'.\n",
    "df_only_USA['country'] = df_only_USA['country'].replace(df_only_USA['country'].value_counts().head(5).index, 'US')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the count of each unique country again now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country\n",
       "US                          20764\n",
       "USA                           467\n",
       "Usa                           448\n",
       "United States of America      427\n",
       "United states                 208\n",
       "                            ...  \n",
       "Saudi Arabia                    1\n",
       "LOUTRELAND                      1\n",
       "philippines                     1\n",
       "Myanmar                         1\n",
       "Burma                           1\n",
       "Name: count, Length: 225, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count again.\n",
    "\n",
    "#didnt work\n",
    "\n",
    "df_only_USA['country'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you notice anything interesting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BONUS CREDIT: resolve [most of] those anomalous cases too without exhaustively taking every variant literally into account.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# BONUS CREDIT: if you’ve resolved it, let’s see how well you did by counting the number of instances of each unique value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It’s looking good so far. Let’s find out the minimum, mean, and maximum (in that order) salary by state, sorted by the mean in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "agg function failed [how->mean,dtype->object]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1943\u001b[39m, in \u001b[36mGroupBy._agg_py_fallback\u001b[39m\u001b[34m(self, how, values, ndim, alt)\u001b[39m\n\u001b[32m   1942\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1943\u001b[39m     res_values = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_grouper\u001b[49m\u001b[43m.\u001b[49m\u001b[43magg_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1944\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/groupby/ops.py:864\u001b[39m, in \u001b[36mBaseGrouper.agg_series\u001b[39m\u001b[34m(self, obj, func, preserve_dtype)\u001b[39m\n\u001b[32m    862\u001b[39m     preserve_dtype = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m864\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_aggregate_series_pure_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    866\u001b[39m npvalues = lib.maybe_convert_objects(result, try_float=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/groupby/ops.py:885\u001b[39m, in \u001b[36mBaseGrouper._aggregate_series_pure_python\u001b[39m\u001b[34m(self, obj, func)\u001b[39m\n\u001b[32m    884\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(splitter):\n\u001b[32m--> \u001b[39m\u001b[32m885\u001b[39m     res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    886\u001b[39m     res = extract_result(res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:2460\u001b[39m, in \u001b[36mGroupBy.mean.<locals>.<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m   2457\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2458\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._cython_agg_general(\n\u001b[32m   2459\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m-> \u001b[39m\u001b[32m2460\u001b[39m         alt=\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   2461\u001b[39m         numeric_only=numeric_only,\n\u001b[32m   2462\u001b[39m     )\n\u001b[32m   2463\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result.__finalize__(\u001b[38;5;28mself\u001b[39m.obj, method=\u001b[33m\"\u001b[39m\u001b[33mgroupby\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/series.py:6560\u001b[39m, in \u001b[36mSeries.mean\u001b[39m\u001b[34m(self, axis, skipna, numeric_only, **kwargs)\u001b[39m\n\u001b[32m   6552\u001b[39m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m, ndim=\u001b[32m1\u001b[39m))\n\u001b[32m   6553\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmean\u001b[39m(\n\u001b[32m   6554\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   6558\u001b[39m     **kwargs,\n\u001b[32m   6559\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m6560\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNDFrame\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/generic.py:12439\u001b[39m, in \u001b[36mNDFrame.mean\u001b[39m\u001b[34m(self, axis, skipna, numeric_only, **kwargs)\u001b[39m\n\u001b[32m  12432\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmean\u001b[39m(\n\u001b[32m  12433\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m  12434\u001b[39m     axis: Axis | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[32m0\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m  12437\u001b[39m     **kwargs,\n\u001b[32m  12438\u001b[39m ) -> Series | \u001b[38;5;28mfloat\u001b[39m:\n\u001b[32m> \u001b[39m\u001b[32m12439\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  12440\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnanmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m  12441\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/generic.py:12396\u001b[39m, in \u001b[36mNDFrame._stat_function\u001b[39m\u001b[34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[39m\n\u001b[32m  12394\u001b[39m validate_bool_kwarg(skipna, \u001b[33m\"\u001b[39m\u001b[33mskipna\u001b[39m\u001b[33m\"\u001b[39m, none_allowed=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m> \u001b[39m\u001b[32m12396\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  12397\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnumeric_only\u001b[49m\n\u001b[32m  12398\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/series.py:6468\u001b[39m, in \u001b[36mSeries._reduce\u001b[39m\u001b[34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[39m\n\u001b[32m   6464\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m   6465\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   6466\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mwith non-numeric dtypes.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   6467\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m6468\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/nanops.py:147\u001b[39m, in \u001b[36mbottleneck_switch.__call__.<locals>.f\u001b[39m\u001b[34m(values, axis, skipna, **kwds)\u001b[39m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     result = \u001b[43malt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/nanops.py:404\u001b[39m, in \u001b[36m_datetimelike_compat.<locals>.new_func\u001b[39m\u001b[34m(values, axis, skipna, mask, **kwargs)\u001b[39m\n\u001b[32m    402\u001b[39m     mask = isna(values)\n\u001b[32m--> \u001b[39m\u001b[32m404\u001b[39m result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/nanops.py:720\u001b[39m, in \u001b[36mnanmean\u001b[39m\u001b[34m(values, axis, skipna, mask)\u001b[39m\n\u001b[32m    719\u001b[39m the_sum = values.sum(axis, dtype=dtype_sum)\n\u001b[32m--> \u001b[39m\u001b[32m720\u001b[39m the_sum = \u001b[43m_ensure_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthe_sum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    722\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[33m\"\u001b[39m\u001b[33mndim\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/nanops.py:1701\u001b[39m, in \u001b[36m_ensure_numeric\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m   1699\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m   1700\u001b[39m     \u001b[38;5;66;03m# GH#44008, GH#36703 avoid casting e.g. strings to numeric\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1701\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not convert string \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m to numeric\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1702\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mTypeError\u001b[39m: Could not convert string '53,000111,43351,00060,00088,00078,00040,00026,00070,000107,00063,00071,00051,00037,79635,60082,00075,000115,000173,00052,00051,07929,07852,00045,60028,00031,20090,00077,00076,00030,00078,00075,000114,00042,30070,00055,00072,00049,500166,00070,50052,00052,50045,000135,000235,00029,12077,00015,00042,00040,000180,00074,55424,96044,20050,00031,20089,00055,0005465,000105,00046,00051,000110,26991,00052,0003,600,00050,000135,00061,000175,00066,00085,00047,40045,000120,00078,00032,864580005200045000800005000080000850005033685000870009000050000125500670009750042000700005500031000560007000060000318008400056000120000423719500035000010100000538002280010500064000697533500020000565900077651200002000035000' to numeric",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[71]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Find the minimum, mean, and maximum salary in USD by U.S. state.\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#df_salary.info()\u001b[39;00m\n\u001b[32m      5\u001b[39m gb_state = df_salary.groupby(\u001b[33m'\u001b[39m\u001b[33mstate\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m salary_by_state = \u001b[43mgb_state\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msalary\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmin\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmax\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(salary_by_state)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/groupby/generic.py:257\u001b[39m, in \u001b[36mSeriesGroupBy.aggregate\u001b[39m\u001b[34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[39m\n\u001b[32m    255\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mengine\u001b[39m\u001b[33m\"\u001b[39m] = engine\n\u001b[32m    256\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mengine_kwargs\u001b[39m\u001b[33m\"\u001b[39m] = engine_kwargs\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_aggregate_multiple_funcs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m relabeling:\n\u001b[32m    259\u001b[39m     \u001b[38;5;66;03m# columns is not narrowed by mypy from relabeling flag\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# for mypy\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/groupby/generic.py:362\u001b[39m, in \u001b[36mSeriesGroupBy._aggregate_multiple_funcs\u001b[39m\u001b[34m(self, arg, *args, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m idx, (name, func) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(arg):\n\u001b[32m    361\u001b[39m         key = base.OutputKey(label=name, position=idx)\n\u001b[32m--> \u001b[39m\u001b[32m362\u001b[39m         results[key] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maggregate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, DataFrame) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m results.values()):\n\u001b[32m    365\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m concat\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/groupby/generic.py:249\u001b[39m, in \u001b[36mSeriesGroupBy.aggregate\u001b[39m\u001b[34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[39m\n\u001b[32m    247\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m engine_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    248\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mengine_kwargs\u001b[39m\u001b[33m\"\u001b[39m] = engine_kwargs\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func, abc.Iterable):\n\u001b[32m    252\u001b[39m     \u001b[38;5;66;03m# Catch instances of lists / tuples\u001b[39;00m\n\u001b[32m    253\u001b[39m     \u001b[38;5;66;03m# but not the class list / tuple itself.\u001b[39;00m\n\u001b[32m    254\u001b[39m     func = maybe_mangle_lambdas(func)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:2458\u001b[39m, in \u001b[36mGroupBy.mean\u001b[39m\u001b[34m(self, numeric_only, engine, engine_kwargs)\u001b[39m\n\u001b[32m   2451\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._numba_agg_general(\n\u001b[32m   2452\u001b[39m         grouped_mean,\n\u001b[32m   2453\u001b[39m         executor.float_dtype_mapping,\n\u001b[32m   2454\u001b[39m         engine_kwargs,\n\u001b[32m   2455\u001b[39m         min_periods=\u001b[32m0\u001b[39m,\n\u001b[32m   2456\u001b[39m     )\n\u001b[32m   2457\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2458\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cython_agg_general\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2459\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2460\u001b[39m \u001b[43m        \u001b[49m\u001b[43malt\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2461\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2462\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2463\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result.__finalize__(\u001b[38;5;28mself\u001b[39m.obj, method=\u001b[33m\"\u001b[39m\u001b[33mgroupby\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:2004\u001b[39m, in \u001b[36mGroupBy._cython_agg_general\u001b[39m\u001b[34m(self, how, alt, numeric_only, min_count, **kwargs)\u001b[39m\n\u001b[32m   2001\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._agg_py_fallback(how, values, ndim=data.ndim, alt=alt)\n\u001b[32m   2002\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m-> \u001b[39m\u001b[32m2004\u001b[39m new_mgr = \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgrouped_reduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2005\u001b[39m res = \u001b[38;5;28mself\u001b[39m._wrap_agged_manager(new_mgr)\n\u001b[32m   2006\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m how \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33midxmin\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33midxmax\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/internals/base.py:367\u001b[39m, in \u001b[36mSingleDataManager.grouped_reduce\u001b[39m\u001b[34m(self, func)\u001b[39m\n\u001b[32m    365\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgrouped_reduce\u001b[39m(\u001b[38;5;28mself\u001b[39m, func):\n\u001b[32m    366\u001b[39m     arr = \u001b[38;5;28mself\u001b[39m.array\n\u001b[32m--> \u001b[39m\u001b[32m367\u001b[39m     res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    368\u001b[39m     index = default_index(\u001b[38;5;28mlen\u001b[39m(res))\n\u001b[32m    370\u001b[39m     mgr = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).from_array(res, index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:2001\u001b[39m, in \u001b[36mGroupBy._cython_agg_general.<locals>.array_func\u001b[39m\u001b[34m(values)\u001b[39m\n\u001b[32m   1998\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m   2000\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m alt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2001\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_agg_py_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malt\u001b[49m\u001b[43m=\u001b[49m\u001b[43malt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2002\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1947\u001b[39m, in \u001b[36mGroupBy._agg_py_fallback\u001b[39m\u001b[34m(self, how, values, ndim, alt)\u001b[39m\n\u001b[32m   1945\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33magg function failed [how->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhow\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,dtype->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mser.dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1946\u001b[39m     \u001b[38;5;66;03m# preserve the kind of exception that raised\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1947\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(err)(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   1949\u001b[39m dtype = ser.dtype\n\u001b[32m   1950\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype == \u001b[38;5;28mobject\u001b[39m:\n",
      "\u001b[31mTypeError\u001b[39m: agg function failed [how->mean,dtype->object]"
     ]
    }
   ],
   "source": [
    "# Find the minimum, mean, and maximum salary in USD by U.S. state.\n",
    "\n",
    "#df_salary.info()\n",
    "\n",
    "gb_state = df_salary.groupby('state')\n",
    "salary_by_state = gb_state['salary'].agg(['min', 'mean', 'max'])\n",
    "\n",
    "print(salary_by_state)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, pooh! We forgot that `salary` isn’t numeric. Something wrong must be fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix it.\n",
    "\n",
    "df_salary['salary'] = pd.to_numeric(df_salary['salary'], errors= 'coerce')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s try that again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   min          mean        max\n",
      "state                                                          \n",
      "Alabama                            0.0  65524.911111   350000.0\n",
      "Alabama, Alaska, Arizona          15.0     15.000000       15.0\n",
      "Alabama, California            29120.0  29120.000000    29120.0\n",
      "Alabama, District of Columbia      NaN           NaN        NaN\n",
      "Alabama, Kansas                    NaN           NaN        NaN\n",
      "...                                ...           ...        ...\n",
      "Virginia                          57.0  96219.045455  1300000.0\n",
      "Washington                        72.0  98032.896552   300000.0\n",
      "West Virginia                      0.0  52754.375000   120000.0\n",
      "Wisconsin                          1.0  83000.628788   920000.0\n",
      "Wyoming                        42500.0  59906.333333    98000.0\n",
      "\n",
      "[134 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Try it again. Yeah!\n",
    "\n",
    "gb_state = df_salary.groupby('state')\n",
    "salary_by_state = gb_state['salary'].agg(['min', 'mean', 'max'])\n",
    "\n",
    "print(salary_by_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That did the trick! Now let’s narrow this to data 2021 and 2022 just because (lel). *(Hint: that timestamp column may not be a temporal type right now.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data to within 2021, 2022, or 2023, saving the DataFrame to a new variable, and generate the summary again.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "Clearly, we do not have enough data to produce useful figures for the level of specificity you’ve now reached. What do you notice about Delaware and West Virginia?\n",
    "\n",
    "Let’s back out a bit and return to `df_salary` (which was the loaded data with renamed columns but *sans* filtering)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus #0\n",
    "\n",
    "Apply the same steps as before to `df_salary`, but do not filter for any specific industry. Do perform the other data cleaning stuff, and get to a point where you can generate the minimum, mean, and maximum by state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus #1\n",
    "\n",
    "This time, format the table output nicely (*$12,345.00*) without modifying the values in the `DataFrame`. That is, `df_salary` should be identical before versus after running your code.\n",
    "\n",
    "(*Hint: if you run into an error about `jinja2` perhaps you need to `pip install` something.*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus #2\n",
    "\n",
    "Filter out the non-single-states (e.g., `'California, Colorado'`) in the most elegant way possible (i.e., *not* by blacklisting all the bad values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus #3\n",
    "\n",
    "Show the quantiles instead of just minimum, mean, and maximum―say 0%, 5%, 25%, 50%, 75%, 95%, and 100%. Outliers may be deceiving.\n",
    "\n",
    "Sort by whatever interests you―like say the *50th* percentile.\n",
    "\n",
    "And throw in a count by state too. It would be interesting to know how many data points contribute to the figures for each state. (*Hint: your nice formatting from Bonus #1 might not work this time around.* 😜)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
